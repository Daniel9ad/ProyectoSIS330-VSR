{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgCs7dGcNVGc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ETCcaQGNNWp",
        "outputId": "d7237b17-09a0-4503-bb92-e3539a21e8cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python) (0.18.3)\n",
            "Installing collected packages: ffmpeg-python\n",
            "Successfully installed ffmpeg-python-0.2.0\n",
            "Collecting av\n",
            "  Downloading av-12.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.8/33.8 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: av\n",
            "Successfully installed av-12.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install ffmpeg-python\n",
        "!pip install av"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZlrG64BUNYe"
      },
      "source": [
        "# Librerias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xREsj1urUPos"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "import torchvision\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from skimage import transform as tf\n",
        "from tqdm import tqdm\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jLgxJNjUvK0"
      },
      "source": [
        "# MediaPipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6iuJF2_VXmWh"
      },
      "outputs": [],
      "source": [
        "!pip install mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkGKjc61XbJJ"
      },
      "outputs": [],
      "source": [
        "import mediapipe as mp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TAzoxo8XVxj"
      },
      "outputs": [],
      "source": [
        "class LandmarksDetector:\n",
        "    def __init__(self):\n",
        "        self.mp_face_detection = mp.solutions.face_detection\n",
        "        self.short_range_detector = self.mp_face_detection.FaceDetection(min_detection_confidence=0.5, model_selection=0)\n",
        "        self.full_range_detector = self.mp_face_detection.FaceDetection(min_detection_confidence=0.5, model_selection=1)\n",
        "\n",
        "    def __call__(self, video_frames):\n",
        "        landmarks = self.detect(video_frames, self.full_range_detector)\n",
        "        if all(element is None for element in landmarks):\n",
        "            landmarks = self.detect(video_frames, self.short_range_detector)\n",
        "            assert any(l is not None for l in landmarks), \"Cannot detect any frames in the video\"\n",
        "        return landmarks\n",
        "\n",
        "    def detect(self, video_frames, detector):\n",
        "        landmarks = []\n",
        "        for frame in video_frames:\n",
        "            results = detector.process(frame)\n",
        "            if not results.detections:\n",
        "                landmarks.append(None)\n",
        "                continue\n",
        "            face_points = []\n",
        "            for idx, detected_faces in enumerate(results.detections):\n",
        "                max_id, max_size = 0, 0\n",
        "                bboxC = detected_faces.location_data.relative_bounding_box\n",
        "                ih, iw, ic = frame.shape\n",
        "                bbox = int(bboxC.xmin * iw), int(bboxC.ymin * ih), int(bboxC.width * iw), int(bboxC.height * ih)\n",
        "                bbox_size = (bbox[2] - bbox[0]) + (bbox[3] - bbox[1])\n",
        "                if bbox_size > max_size:\n",
        "                    max_id, max_size = idx, bbox_size\n",
        "                lmx = [\n",
        "                    [int(detected_faces.location_data.relative_keypoints[self.mp_face_detection.FaceKeyPoint(0).value].x * iw),\n",
        "                     int(detected_faces.location_data.relative_keypoints[self.mp_face_detection.FaceKeyPoint(0).value].y * ih)],\n",
        "                    [int(detected_faces.location_data.relative_keypoints[self.mp_face_detection.FaceKeyPoint(1).value].x * iw),\n",
        "                     int(detected_faces.location_data.relative_keypoints[self.mp_face_detection.FaceKeyPoint(1).value].y * ih)],\n",
        "                    [int(detected_faces.location_data.relative_keypoints[self.mp_face_detection.FaceKeyPoint(2).value].x * iw),\n",
        "                     int(detected_faces.location_data.relative_keypoints[self.mp_face_detection.FaceKeyPoint(2).value].y * ih)],\n",
        "                    [int(detected_faces.location_data.relative_keypoints[self.mp_face_detection.FaceKeyPoint(3).value].x * iw),\n",
        "                     int(detected_faces.location_data.relative_keypoints[self.mp_face_detection.FaceKeyPoint(3).value].y * ih)],\n",
        "                    ]\n",
        "                face_points.append(lmx)\n",
        "            landmarks.append(np.array(face_points[max_id]))\n",
        "        return landmarks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6ahhX7gXohu"
      },
      "outputs": [],
      "source": [
        "reference = np.array([[ 70.92383848,  97.13757949],[ 72.62515288, 114.90361188],\n",
        "  [ 75.98941827, 131.07402473],[ 79.26959318, 146.2116596 ],[ 83.61348894, 163.26020701],\n",
        "  [ 91.33134186, 177.44535288],[100.27169245, 187.0885567 ],[112.12435016, 196.00353535],\n",
        "  [130.74175801, 200.52998862],[149.8553027 , 195.31198065],[163.101687  , 186.44060881],\n",
        "  [173.65334172, 176.57250158],[182.43614459, 162.27992572],[187.16738556, 145.09391978],\n",
        "  [190.22905333, 129.72418731],[193.02118502, 113.45923358],[194.43863372,  95.5795392 ],\n",
        "  [ 81.33095967,  80.79544511],[ 87.75906556,  75.27980275],[ 96.22692544,  73.83857497],\n",
        "  [104.55524335,  74.74029382],[112.23186144,  76.97670954],[144.49576387,  76.42387471],\n",
        "  [152.34799901,  73.83329748],[161.13054079,  72.63570385],[170.58715674,  73.84785054],\n",
        "  [178.21409885,  79.43802857],[128.7337425 ,  95.35962566],[128.48854473, 106.92459506],\n",
        "  [128.24475936, 118.27285086],[128.26596547, 127.69870727],[118.76000113, 135.19357677],\n",
        "  [122.96307973, 136.14619774],[128.87017961, 137.30253356],[134.9428314 , 135.99720543],\n",
        "  [139.48259748, 134.87763793],[ 92.52245553,  94.36876014],[ 97.58518219,  90.95977781],\n",
        "  [105.41368273,  90.91345887],[112.77241724,  94.9436087 ],[106.103635  ,  97.08485693],\n",
        "  [ 98.04628565,  97.36335869],[145.52511509,  94.53499862],[152.58953438,  90.21485666],\n",
        "  [160.61170666,  90.19938514],[166.67710071,  93.56562296],[160.55971572,  96.48125958],\n",
        "  [152.20465993,  96.47281336],[107.16760614, 157.19606764],[114.47611216, 152.12006957],\n",
        "  [123.84852759, 148.51863199],[128.97628288, 149.41552527],[134.14360703, 148.42628211],\n",
        "  [144.17717842, 151.79343262],[152.19284005, 156.98711116],[143.85966895, 164.00347101],\n",
        "  [136.7441507 , 167.9430006 ],[129.15278278, 168.81853366],[121.79511074, 168.02271929],\n",
        "  [115.27508573, 164.15159355],[109.23088653, 157.00172103],[122.50270762, 154.40733649],\n",
        "  [129.02862236, 154.12104227],[135.83648069, 154.31214998],[150.75782809, 156.79506004],\n",
        "  [135.66204627, 160.62976732],[128.95218547, 161.28762709],[122.48775432, 160.50878431]])\n",
        "\n",
        "def linear_interpolate(landmarks, start_idx, stop_idx):\n",
        "    start_landmarks = landmarks[start_idx]\n",
        "    stop_landmarks = landmarks[stop_idx]\n",
        "    delta = stop_landmarks - start_landmarks\n",
        "    for idx in range(1, stop_idx - start_idx):\n",
        "        landmarks[start_idx + idx] = (\n",
        "            start_landmarks + idx / float(stop_idx - start_idx) * delta\n",
        "        )\n",
        "    return landmarks\n",
        "\n",
        "\n",
        "def warp_img(src, dst, img, std_size):\n",
        "    tform = tf.estimate_transform(\"similarity\", src, dst)\n",
        "    warped = tf.warp(img, inverse_map=tform.inverse, output_shape=std_size)\n",
        "    warped = (warped * 255).astype(\"uint8\")\n",
        "    return warped, tform\n",
        "\n",
        "\n",
        "def apply_transform(transform, img, std_size):\n",
        "    warped = tf.warp(img, inverse_map=transform.inverse, output_shape=std_size)\n",
        "    warped = (warped * 255).astype(\"uint8\")\n",
        "    return warped\n",
        "\n",
        "\n",
        "def cut_patch(img, landmarks, height, width, threshold=5):\n",
        "    center_x, center_y = np.mean(landmarks, axis=0)\n",
        "    # Check for too much bias in height and width\n",
        "    if abs(center_y - img.shape[0] / 2) > height + threshold:\n",
        "        raise OverflowError(\"too much bias in height\")\n",
        "    if abs(center_x - img.shape[1] / 2) > width + threshold:\n",
        "        raise OverflowError(\"too much bias in width\")\n",
        "    # Calculate bounding box coordinates\n",
        "    y_min = int(round(np.clip(center_y - height, 0, img.shape[0])))\n",
        "    y_max = int(round(np.clip(center_y + height, 0, img.shape[0])))\n",
        "    x_min = int(round(np.clip(center_x - width, 0, img.shape[1])))\n",
        "    x_max = int(round(np.clip(center_x + width, 0, img.shape[1])))\n",
        "    # Cut the image\n",
        "    cutted_img = np.copy(img[y_min:y_max, x_min:x_max])\n",
        "    return cutted_img\n",
        "\n",
        "\n",
        "class VideoProcess:\n",
        "    def __init__(\n",
        "        self,\n",
        "        mean_face_path=\"20words_mean_face.npy\",\n",
        "        crop_width=96,\n",
        "        crop_height=96,\n",
        "        start_idx=3,\n",
        "        stop_idx=4,\n",
        "        window_margin=12,\n",
        "        convert_gray=True,\n",
        "    ):\n",
        "        # self.reference = np.load(\n",
        "        #     os.path.join(os.path.dirname(__file__), mean_face_path)\n",
        "        # )\n",
        "        self.reference = reference\n",
        "        self.crop_width = crop_width\n",
        "        self.crop_height = crop_height\n",
        "        self.start_idx = start_idx\n",
        "        self.stop_idx = stop_idx\n",
        "        self.window_margin = window_margin\n",
        "        self.convert_gray = convert_gray\n",
        "\n",
        "    def __call__(self, video, landmarks):\n",
        "        # Pre-process landmarks: interpolate frames that are not detected\n",
        "        preprocessed_landmarks = self.interpolate_landmarks(landmarks)\n",
        "        # Exclude corner cases: no landmark in all frames\n",
        "        if not preprocessed_landmarks:\n",
        "            return\n",
        "        # Affine transformation and crop patch\n",
        "        sequence = self.crop_patch(video, preprocessed_landmarks)\n",
        "        assert sequence is not None, \"crop an empty patch.\"\n",
        "        return sequence\n",
        "\n",
        "    def crop_patch(self, video, landmarks):\n",
        "        sequence = []\n",
        "        for frame_idx, frame in enumerate(video):\n",
        "            window_margin = min(\n",
        "                self.window_margin // 2, frame_idx, len(landmarks) - 1 - frame_idx\n",
        "            )\n",
        "            smoothed_landmarks = np.mean(\n",
        "                [\n",
        "                    landmarks[x]\n",
        "                    for x in range(\n",
        "                        frame_idx - window_margin, frame_idx + window_margin + 1\n",
        "                    )\n",
        "                ],\n",
        "                axis=0,\n",
        "            )\n",
        "            smoothed_landmarks += landmarks[frame_idx].mean(\n",
        "                axis=0\n",
        "            ) - smoothed_landmarks.mean(axis=0)\n",
        "            transformed_frame, transformed_landmarks = self.affine_transform(\n",
        "                frame, smoothed_landmarks, self.reference, grayscale=self.convert_gray\n",
        "            )\n",
        "            patch = cut_patch(\n",
        "                transformed_frame,\n",
        "                transformed_landmarks[self.start_idx : self.stop_idx],\n",
        "                self.crop_height // 2,\n",
        "                self.crop_width // 2,\n",
        "            )\n",
        "            sequence.append(patch)\n",
        "        return np.array(sequence)\n",
        "\n",
        "    def interpolate_landmarks(self, landmarks):\n",
        "        valid_frames_idx = [idx for idx, lm in enumerate(landmarks) if lm is not None]\n",
        "\n",
        "        if not valid_frames_idx:\n",
        "            return None\n",
        "\n",
        "        for idx in range(1, len(valid_frames_idx)):\n",
        "            if valid_frames_idx[idx] - valid_frames_idx[idx - 1] > 1:\n",
        "                landmarks = linear_interpolate(\n",
        "                    landmarks, valid_frames_idx[idx - 1], valid_frames_idx[idx]\n",
        "                )\n",
        "\n",
        "        valid_frames_idx = [idx for idx, lm in enumerate(landmarks) if lm is not None]\n",
        "\n",
        "        # Handle corner case: keep frames at the beginning or at the end that failed to be detected\n",
        "        if valid_frames_idx:\n",
        "            landmarks[: valid_frames_idx[0]] = [\n",
        "                landmarks[valid_frames_idx[0]]\n",
        "            ] * valid_frames_idx[0]\n",
        "            landmarks[valid_frames_idx[-1] :] = [landmarks[valid_frames_idx[-1]]] * (\n",
        "                len(landmarks) - valid_frames_idx[-1]\n",
        "            )\n",
        "\n",
        "        assert all(lm is not None for lm in landmarks), \"not every frame has landmark\"\n",
        "\n",
        "        return landmarks\n",
        "\n",
        "    def affine_transform(\n",
        "        self,\n",
        "        frame,\n",
        "        landmarks,\n",
        "        reference,\n",
        "        grayscale=False,\n",
        "        target_size=(256, 256),\n",
        "        reference_size=(256, 256),\n",
        "        stable_points=(0, 1, 2, 3),\n",
        "        interpolation=cv2.INTER_LINEAR,\n",
        "        border_mode=cv2.BORDER_CONSTANT,\n",
        "        border_value=0,\n",
        "    ):\n",
        "        if grayscale:\n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
        "        stable_reference = self.get_stable_reference(\n",
        "            reference, reference_size, target_size\n",
        "        )\n",
        "        transform = self.estimate_affine_transform(\n",
        "            landmarks, stable_points, stable_reference\n",
        "        )\n",
        "        transformed_frame, transformed_landmarks = self.apply_affine_transform(\n",
        "            frame,\n",
        "            landmarks,\n",
        "            transform,\n",
        "            target_size,\n",
        "            interpolation,\n",
        "            border_mode,\n",
        "            border_value,\n",
        "        )\n",
        "\n",
        "        return transformed_frame, transformed_landmarks\n",
        "\n",
        "    def get_stable_reference(self, reference, reference_size, target_size):\n",
        "        # -- right eye, left eye, nose tip, mouth center\n",
        "        stable_reference = np.vstack(\n",
        "            [\n",
        "                np.mean(reference[36:42], axis=0),\n",
        "                np.mean(reference[42:48], axis=0),\n",
        "                np.mean(reference[31:36], axis=0),\n",
        "                np.mean(reference[48:68], axis=0),\n",
        "            ]\n",
        "        )\n",
        "        stable_reference[:, 0] -= (reference_size[0] - target_size[0]) / 2.0\n",
        "        stable_reference[:, 1] -= (reference_size[1] - target_size[1]) / 2.0\n",
        "        return stable_reference\n",
        "\n",
        "    def estimate_affine_transform(self, landmarks, stable_points, stable_reference):\n",
        "        return cv2.estimateAffinePartial2D(\n",
        "            np.vstack([landmarks[x] for x in stable_points]),\n",
        "            stable_reference,\n",
        "            method=cv2.LMEDS,\n",
        "        )[0]\n",
        "\n",
        "    def apply_affine_transform(\n",
        "        self,\n",
        "        frame,\n",
        "        landmarks,\n",
        "        transform,\n",
        "        target_size,\n",
        "        interpolation,\n",
        "        border_mode,\n",
        "        border_value,\n",
        "    ):\n",
        "        transformed_frame = cv2.warpAffine(\n",
        "            frame,\n",
        "            transform,\n",
        "            dsize=(target_size[0], target_size[1]),\n",
        "            flags=interpolation,\n",
        "            borderMode=border_mode,\n",
        "            borderValue=border_value,\n",
        "        )\n",
        "        transformed_landmarks = (\n",
        "            np.matmul(landmarks, transform[:, :2].transpose())\n",
        "            + transform[:, 2].transpose()\n",
        "        )\n",
        "        return transformed_frame, transformed_landmarks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rIk5Xf7Urtz"
      },
      "source": [
        "# RetinaFace and FAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZE9lkZSTV0YI",
        "outputId": "6688a8b4-c05c-4ddf-89b7-a4d8eba08188"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'face_alignment'...\n",
            "remote: Enumerating objects: 190, done.\u001b[K\n",
            "remote: Counting objects: 100% (32/32), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 190 (delta 27), reused 27 (delta 26), pack-reused 158\u001b[K\n",
            "Receiving objects: 100% (190/190), 213.82 MiB | 24.49 MiB/s, done.\n",
            "Resolving deltas: 100% (84/84), done.\n",
            "Updating files: 100% (14/14), done.\n",
            "Cloning into 'face_detection'...\n",
            "remote: Enumerating objects: 300, done.\u001b[K\n",
            "remote: Counting objects: 100% (50/50), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 300 (delta 41), reused 39 (delta 39), pack-reused 250\u001b[K\n",
            "Receiving objects: 100% (300/300), 81.19 MiB | 30.52 MiB/s, done.\n",
            "Resolving deltas: 100% (141/141), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/hhj1897/face_alignment.git\n",
        "!git clone https://github.com/hhj1897/face_detection.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_IOSBvMV4ox"
      },
      "outputs": [],
      "source": [
        "from face_detection.ibug.face_detection import RetinaFacePredictor\n",
        "from face_alignment.ibug.face_alignment import FANPredictor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2_Tl0YFUu2N"
      },
      "outputs": [],
      "source": [
        "class LandmarksDetector:\n",
        "    def __init__(self, device=\"cuda:0\", model_name=\"resnet50\"):\n",
        "        self.face_detector = RetinaFacePredictor(\n",
        "            device=device,\n",
        "            threshold=0.8,\n",
        "            model=RetinaFacePredictor.get_model(model_name),\n",
        "        )\n",
        "        self.landmark_detector = FANPredictor(device=device, model=None)\n",
        "\n",
        "    def __call__(self, video_frames):\n",
        "        landmarks = []\n",
        "        for frame in video_frames:\n",
        "            detected_faces = self.face_detector(frame, rgb=False)\n",
        "            face_points, _ = self.landmark_detector(frame, detected_faces, rgb=True)\n",
        "            if len(detected_faces) == 0:\n",
        "                landmarks.append(None)\n",
        "            else:\n",
        "                max_id, max_size = 0, 0\n",
        "                for idx, bbox in enumerate(detected_faces):\n",
        "                    bbox_size = (bbox[2] - bbox[0]) + (bbox[3] - bbox[1])\n",
        "                    if bbox_size > max_size:\n",
        "                        max_id, max_size = idx, bbox_size\n",
        "                landmarks.append(face_points[max_id])\n",
        "        return landmarks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAVsQMOLWsGp"
      },
      "outputs": [],
      "source": [
        "reference = np.array([[ 70.92383848,  97.13757949],[ 72.62515288, 114.90361188],\n",
        "  [ 75.98941827, 131.07402473],[ 79.26959318, 146.2116596 ],[ 83.61348894, 163.26020701],\n",
        "  [ 91.33134186, 177.44535288],[100.27169245, 187.0885567 ],[112.12435016, 196.00353535],\n",
        "  [130.74175801, 200.52998862],[149.8553027 , 195.31198065],[163.101687  , 186.44060881],\n",
        "  [173.65334172, 176.57250158],[182.43614459, 162.27992572],[187.16738556, 145.09391978],\n",
        "  [190.22905333, 129.72418731],[193.02118502, 113.45923358],[194.43863372,  95.5795392 ],\n",
        "  [ 81.33095967,  80.79544511],[ 87.75906556,  75.27980275],[ 96.22692544,  73.83857497],\n",
        "  [104.55524335,  74.74029382],[112.23186144,  76.97670954],[144.49576387,  76.42387471],\n",
        "  [152.34799901,  73.83329748],[161.13054079,  72.63570385],[170.58715674,  73.84785054],\n",
        "  [178.21409885,  79.43802857],[128.7337425 ,  95.35962566],[128.48854473, 106.92459506],\n",
        "  [128.24475936, 118.27285086],[128.26596547, 127.69870727],[118.76000113, 135.19357677],\n",
        "  [122.96307973, 136.14619774],[128.87017961, 137.30253356],[134.9428314 , 135.99720543],\n",
        "  [139.48259748, 134.87763793],[ 92.52245553,  94.36876014],[ 97.58518219,  90.95977781],\n",
        "  [105.41368273,  90.91345887],[112.77241724,  94.9436087 ],[106.103635  ,  97.08485693],\n",
        "  [ 98.04628565,  97.36335869],[145.52511509,  94.53499862],[152.58953438,  90.21485666],\n",
        "  [160.61170666,  90.19938514],[166.67710071,  93.56562296],[160.55971572,  96.48125958],\n",
        "  [152.20465993,  96.47281336],[107.16760614, 157.19606764],[114.47611216, 152.12006957],\n",
        "  [123.84852759, 148.51863199],[128.97628288, 149.41552527],[134.14360703, 148.42628211],\n",
        "  [144.17717842, 151.79343262],[152.19284005, 156.98711116],[143.85966895, 164.00347101],\n",
        "  [136.7441507 , 167.9430006 ],[129.15278278, 168.81853366],[121.79511074, 168.02271929],\n",
        "  [115.27508573, 164.15159355],[109.23088653, 157.00172103],[122.50270762, 154.40733649],\n",
        "  [129.02862236, 154.12104227],[135.83648069, 154.31214998],[150.75782809, 156.79506004],\n",
        "  [135.66204627, 160.62976732],[128.95218547, 161.28762709],[122.48775432, 160.50878431]])\n",
        "\n",
        "def linear_interpolate(landmarks, start_idx, stop_idx):\n",
        "    start_landmarks = landmarks[start_idx]\n",
        "    stop_landmarks = landmarks[stop_idx]\n",
        "    delta = stop_landmarks - start_landmarks\n",
        "    for idx in range(1, stop_idx - start_idx):\n",
        "        landmarks[start_idx + idx] = (\n",
        "            start_landmarks + idx / float(stop_idx - start_idx) * delta\n",
        "        )\n",
        "    return landmarks\n",
        "\n",
        "\n",
        "def warp_img(src, dst, img, std_size):\n",
        "    tform = tf.estimate_transform(\"similarity\", src, dst)\n",
        "    warped = tf.warp(img, inverse_map=tform.inverse, output_shape=std_size)\n",
        "    warped = (warped * 255).astype(\"uint8\")\n",
        "    return warped, tform\n",
        "\n",
        "\n",
        "def apply_transform(transform, img, std_size):\n",
        "    warped = tf.warp(img, inverse_map=transform.inverse, output_shape=std_size)\n",
        "    warped = (warped * 255).astype(\"uint8\")\n",
        "    return warped\n",
        "\n",
        "\n",
        "def cut_patch(img, landmarks, height, width, threshold=5):\n",
        "    center_x, center_y = np.mean(landmarks, axis=0)\n",
        "    # Check for too much bias in height and width\n",
        "    if abs(center_y - img.shape[0] / 2) > height + threshold:\n",
        "        raise OverflowError(\"too much bias in height\")\n",
        "    if abs(center_x - img.shape[1] / 2) > width + threshold:\n",
        "        raise OverflowError(\"too much bias in width\")\n",
        "    # Calculate bounding box coordinates\n",
        "    y_min = int(round(np.clip(center_y - height, 0, img.shape[0])))\n",
        "    y_max = int(round(np.clip(center_y + height, 0, img.shape[0])))\n",
        "    x_min = int(round(np.clip(center_x - width, 0, img.shape[1])))\n",
        "    x_max = int(round(np.clip(center_x + width, 0, img.shape[1])))\n",
        "    # Cut the image\n",
        "    cutted_img = np.copy(img[y_min:y_max, x_min:x_max])\n",
        "    return cutted_img\n",
        "\n",
        "\n",
        "class VideoProcess:\n",
        "    def __init__(\n",
        "        self,\n",
        "        mean_face_path=\"20words_mean_face.npy\",\n",
        "        crop_width=96,\n",
        "        crop_height=96,\n",
        "        start_idx=48,\n",
        "        stop_idx=68,\n",
        "        window_margin=12,\n",
        "        convert_gray=True,\n",
        "    ):\n",
        "        # self.reference = np.load(\n",
        "        #     os.path.join(os.path.dirname(__file__), mean_face_path)\n",
        "        # )\n",
        "        self.reference = reference\n",
        "        self.crop_width = crop_width\n",
        "        self.crop_height = crop_height\n",
        "        self.start_idx = start_idx\n",
        "        self.stop_idx = stop_idx\n",
        "        self.window_margin = window_margin\n",
        "        self.convert_gray = convert_gray\n",
        "\n",
        "    def __call__(self, video, landmarks):\n",
        "        # Pre-process landmarks: interpolate frames that are not detected\n",
        "        preprocessed_landmarks = self.interpolate_landmarks(landmarks)\n",
        "        # Exclude corner cases: no landmark in all frames or number of frames is less than window length\n",
        "        if (\n",
        "            not preprocessed_landmarks\n",
        "            or len(preprocessed_landmarks) < self.window_margin\n",
        "        ):\n",
        "            return\n",
        "        # Affine transformation and crop patch\n",
        "        sequence = self.crop_patch(video, preprocessed_landmarks)\n",
        "        assert sequence is not None, \"crop an empty patch.\"\n",
        "        return sequence\n",
        "\n",
        "    def crop_patch(self, video, landmarks):\n",
        "        sequence = []\n",
        "        for frame_idx, frame in enumerate(video):\n",
        "            window_margin = min(\n",
        "                self.window_margin // 2, frame_idx, len(landmarks) - 1 - frame_idx\n",
        "            )\n",
        "            smoothed_landmarks = np.mean(\n",
        "                [\n",
        "                    landmarks[x]\n",
        "                    for x in range(\n",
        "                        frame_idx - window_margin, frame_idx + window_margin + 1\n",
        "                    )\n",
        "                ],\n",
        "                axis=0,\n",
        "            )\n",
        "            smoothed_landmarks += landmarks[frame_idx].mean(\n",
        "                axis=0\n",
        "            ) - smoothed_landmarks.mean(axis=0)\n",
        "            transformed_frame, transformed_landmarks = self.affine_transform(\n",
        "                frame, smoothed_landmarks, self.reference, grayscale=self.convert_gray\n",
        "            )\n",
        "            patch = cut_patch(\n",
        "                transformed_frame,\n",
        "                transformed_landmarks[self.start_idx : self.stop_idx],\n",
        "                self.crop_height // 2,\n",
        "                self.crop_width // 2,\n",
        "            )\n",
        "            sequence.append(patch)\n",
        "        return np.array(sequence)\n",
        "\n",
        "    def interpolate_landmarks(self, landmarks):\n",
        "        valid_frames_idx = [idx for idx, lm in enumerate(landmarks) if lm is not None]\n",
        "\n",
        "        if not valid_frames_idx:\n",
        "            return None\n",
        "\n",
        "        for idx in range(1, len(valid_frames_idx)):\n",
        "            if valid_frames_idx[idx] - valid_frames_idx[idx - 1] > 1:\n",
        "                landmarks = linear_interpolate(\n",
        "                    landmarks, valid_frames_idx[idx - 1], valid_frames_idx[idx]\n",
        "                )\n",
        "\n",
        "        valid_frames_idx = [idx for idx, lm in enumerate(landmarks) if lm is not None]\n",
        "\n",
        "        # Handle corner case: keep frames at the beginning or at the end that failed to be detected\n",
        "        if valid_frames_idx:\n",
        "            landmarks[: valid_frames_idx[0]] = [\n",
        "                landmarks[valid_frames_idx[0]]\n",
        "            ] * valid_frames_idx[0]\n",
        "            landmarks[valid_frames_idx[-1] :] = [landmarks[valid_frames_idx[-1]]] * (\n",
        "                len(landmarks) - valid_frames_idx[-1]\n",
        "            )\n",
        "\n",
        "        assert all(lm is not None for lm in landmarks), \"not every frame has landmark\"\n",
        "\n",
        "        return landmarks\n",
        "\n",
        "    def affine_transform(\n",
        "        self,\n",
        "        frame,\n",
        "        landmarks,\n",
        "        reference,\n",
        "        grayscale=True,\n",
        "        target_size=(256, 256),\n",
        "        reference_size=(256, 256),\n",
        "        stable_points=(28, 33, 36, 39, 42, 45, 48, 54),\n",
        "        interpolation=cv2.INTER_LINEAR,\n",
        "        border_mode=cv2.BORDER_CONSTANT,\n",
        "        border_value=0,\n",
        "    ):\n",
        "        if grayscale:\n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
        "        stable_reference = self.get_stable_reference(\n",
        "            reference, stable_points, reference_size, target_size\n",
        "        )\n",
        "        transform = self.estimate_affine_transform(\n",
        "            landmarks, stable_points, stable_reference\n",
        "        )\n",
        "        transformed_frame, transformed_landmarks = self.apply_affine_transform(\n",
        "            frame,\n",
        "            landmarks,\n",
        "            transform,\n",
        "            target_size,\n",
        "            interpolation,\n",
        "            border_mode,\n",
        "            border_value,\n",
        "        )\n",
        "\n",
        "        return transformed_frame, transformed_landmarks\n",
        "\n",
        "    def get_stable_reference(\n",
        "        self, reference, stable_points, reference_size, target_size\n",
        "    ):\n",
        "        stable_reference = np.vstack([reference[x] for x in stable_points])\n",
        "        stable_reference[:, 0] -= (reference_size[0] - target_size[0]) / 2.0\n",
        "        stable_reference[:, 1] -= (reference_size[1] - target_size[1]) / 2.0\n",
        "        return stable_reference\n",
        "\n",
        "    def estimate_affine_transform(self, landmarks, stable_points, stable_reference):\n",
        "        return cv2.estimateAffinePartial2D(\n",
        "            np.vstack([landmarks[x] for x in stable_points]),\n",
        "            stable_reference,\n",
        "            method=cv2.LMEDS,\n",
        "        )[0]\n",
        "\n",
        "    def apply_affine_transform(\n",
        "        self,\n",
        "        frame,\n",
        "        landmarks,\n",
        "        transform,\n",
        "        target_size,\n",
        "        interpolation,\n",
        "        border_mode,\n",
        "        border_value,\n",
        "    ):\n",
        "        transformed_frame = cv2.warpAffine(\n",
        "            frame,\n",
        "            transform,\n",
        "            dsize=(target_size[0], target_size[1]),\n",
        "            flags=interpolation,\n",
        "            borderMode=border_mode,\n",
        "            borderValue=border_value,\n",
        "        )\n",
        "        transformed_landmarks = (\n",
        "            np.matmul(landmarks, transform[:, :2].transpose())\n",
        "            + transform[:, 2].transpose()\n",
        "        )\n",
        "        return transformed_frame, transformed_landmarks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAvtziY3UFbe"
      },
      "source": [
        "# AVSRDataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jQdMjnlNd9e"
      },
      "outputs": [],
      "source": [
        "class AVSRDataLoader:\n",
        "    def __init__(self, modality, detector=\"retinaface\", convert_gray=True):\n",
        "        self.modality = modality\n",
        "        if modality == \"video\":\n",
        "            # if detector == \"retinaface\":\n",
        "            #     from detectors.retinaface.detector import LandmarksDetector\n",
        "            #     from detectors.retinaface.video_process import VideoProcess\n",
        "            #     self.landmarks_detector = LandmarksDetector(device=\"cuda:0\")\n",
        "            #     self.video_process = VideoProcess(convert_gray=convert_gray)\n",
        "\n",
        "            # if detector == \"mediapipe\":\n",
        "            #     from detectors.mediapipe.detector import LandmarksDetector\n",
        "            #     from detectors.mediapipe.video_process import VideoProcess\n",
        "            #     self.landmarks_detector = LandmarksDetector()\n",
        "            #     self.video_process = VideoProcess(convert_gray=convert_gray)\n",
        "            self.landmarks_detector = LandmarksDetector(device=\"cuda:0\")\n",
        "            self.video_process = VideoProcess(convert_gray=convert_gray)\n",
        "\n",
        "    def load_data(self, data_filename, landmarks=None, transform=True):\n",
        "        if self.modality == \"audio\":\n",
        "            audio, sample_rate = self.load_audio(data_filename)\n",
        "            audio = self.audio_process(audio, sample_rate)\n",
        "            return audio\n",
        "        if self.modality == \"video\":\n",
        "            video = self.load_video(data_filename)\n",
        "            if not landmarks:\n",
        "                landmarks = self.landmarks_detector(video)\n",
        "            video = self.video_process(video, landmarks)\n",
        "            if video is None:\n",
        "                raise TypeError(\"video cannot be None\")\n",
        "            video = torch.tensor(video)\n",
        "            return video\n",
        "\n",
        "    def load_audio(self, data_filename):\n",
        "        waveform, sample_rate = torchaudio.load(data_filename, normalize=True)\n",
        "        return waveform, sample_rate\n",
        "\n",
        "    def load_video(self, data_filename):\n",
        "        return torchvision.io.read_video(data_filename, pts_unit=\"sec\")[0].numpy()\n",
        "\n",
        "    def audio_process(self, waveform, sample_rate, target_sample_rate=16000):\n",
        "        if sample_rate != target_sample_rate:\n",
        "            waveform = torchaudio.functional.resample(\n",
        "                waveform, sample_rate, target_sample_rate\n",
        "            )\n",
        "        waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
        "        return waveform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiL6IrYoYdOy"
      },
      "source": [
        "# Util"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zA3biEp1UXj2"
      },
      "outputs": [],
      "source": [
        "def split_file(filename, max_frames=600, fps=25.0):\n",
        "\n",
        "    lines = open(filename).read().splitlines()\n",
        "\n",
        "    flag = 0\n",
        "    stack = []\n",
        "    res = []\n",
        "\n",
        "    tmp = 0\n",
        "    start_timestamp = 0.0\n",
        "\n",
        "    threshold = max_frames / fps\n",
        "\n",
        "    for line in lines:\n",
        "        if \"WORD START END ASDSCORE\" in line:\n",
        "            flag = 1\n",
        "            continue\n",
        "        if flag:\n",
        "            word, start, end, score = line.split(\" \")\n",
        "            start, end, score = float(start), float(end), float(score)\n",
        "            if end < tmp + threshold:\n",
        "                stack.append(word)\n",
        "                last_timestamp = end\n",
        "            else:\n",
        "                res.append(\n",
        "                    [\n",
        "                        \" \".join(stack),\n",
        "                        start_timestamp,\n",
        "                        last_timestamp,\n",
        "                        last_timestamp - start_timestamp,\n",
        "                    ]\n",
        "                )\n",
        "                tmp = start\n",
        "                start_timestamp = start\n",
        "                stack = [word]\n",
        "    if stack:\n",
        "        res.append([\" \".join(stack), start_timestamp, end, end - start_timestamp])\n",
        "    return res\n",
        "\n",
        "\n",
        "def save_vid_txt(\n",
        "    dst_vid_filename, dst_txt_filename, trim_video_data, content, video_fps=25\n",
        "):\n",
        "    # -- save video\n",
        "    save2vid(dst_vid_filename, trim_video_data, video_fps)\n",
        "    # -- save text\n",
        "    os.makedirs(os.path.dirname(dst_txt_filename), exist_ok=True)\n",
        "    f = open(dst_txt_filename, \"w\", encoding=\"utf-8\")\n",
        "    f.write(f\"{content}\")\n",
        "    f.close()\n",
        "\n",
        "\n",
        "def save_vid_aud(\n",
        "    dst_vid_filename,\n",
        "    dst_aud_filename,\n",
        "    trim_vid_data,\n",
        "    trim_aud_data,\n",
        "    video_fps=25,\n",
        "    audio_sample_rate=16000,\n",
        "):\n",
        "    # -- save video\n",
        "    save2vid(dst_vid_filename, trim_vid_data, video_fps)\n",
        "    # -- save audio\n",
        "    save2aud(dst_aud_filename, trim_aud_data, audio_sample_rate)\n",
        "\n",
        "\n",
        "def save_vid_aud_txt(\n",
        "    dst_vid_filename,\n",
        "    dst_aud_filename,\n",
        "    dst_txt_filename,\n",
        "    trim_vid_data,\n",
        "    trim_aud_data,\n",
        "    content,\n",
        "    video_fps=25,\n",
        "    audio_sample_rate=16000,\n",
        "):\n",
        "    # -- save video\n",
        "    if dst_vid_filename is not None:\n",
        "        save2vid(dst_vid_filename, trim_vid_data, video_fps)\n",
        "    # -- save audio\n",
        "    if dst_aud_filename is not None:\n",
        "        save2aud(dst_aud_filename, trim_aud_data, audio_sample_rate)\n",
        "    # -- save text\n",
        "    os.makedirs(os.path.dirname(dst_txt_filename), exist_ok=True)\n",
        "    f = open(dst_txt_filename, \"w\", encoding=\"utf-8\")\n",
        "    f.write(f\"{content}\")\n",
        "    f.close()\n",
        "\n",
        "\n",
        "def save2vid(filename, vid, frames_per_second):\n",
        "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "    torchvision.io.write_video(filename, vid, frames_per_second)\n",
        "\n",
        "\n",
        "def save2aud(filename, aud, sample_rate):\n",
        "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "    torchaudio.save(filename, aud, sample_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SJuNFb_Ycq0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wq50mSe0jOLG"
      },
      "source": [
        "# Whisper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfH5SDeijQTL",
        "outputId": "8eb5630f-f002-47b8-e703-e2a0dd19b69f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-z11vn_0l\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-z11vn_0l\n",
            "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.3.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.4)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper==20231117)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.14.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper==20231117)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802826 sha256=4580cc3d158a4e086dc88d7b968b3c8562d38f2e05a9e4e34d9c87f33a48e085\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ifu_88sv/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 openai-whisper-20231117 tiktoken-0.7.0\n"
          ]
        }
      ],
      "source": [
        "! pip install git+https://github.com/openai/whisper.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQNyCAtujbq6"
      },
      "outputs": [],
      "source": [
        "import whisper\n",
        "from moviepy.editor import VideoFileClip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8w4WWs7okcK1",
        "outputId": "3ea643f7-33c1-4f63-e20f-c2c95593d8ba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████████████████████████████████| 1.42G/1.42G [00:17<00:00, 86.9MiB/s]\n"
          ]
        }
      ],
      "source": [
        "model_whisper = whisper.load_model(\"medium\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHh8cPc_jumK"
      },
      "outputs": [],
      "source": [
        "def obtener_texto(ruta, name):\n",
        "    video = VideoFileClip(ruta)\n",
        "    video.audio.write_audiofile(f'{name}.mp3', logger=None)\n",
        "    i = 0\n",
        "    while True:\n",
        "        result = model_whisper.transcribe(f'{name}.mp3')\n",
        "        temperature = result['segments'][0]['temperature']\n",
        "        compression_ratio = result['segments'][0]['compression_ratio']\n",
        "        no_speech_prob = result['segments'][0]['no_speech_prob']\n",
        "        #print(result)\n",
        "        if temperature == 0.0 and compression_ratio > 0.70:\n",
        "            text = result['text']\n",
        "            break\n",
        "        elif temperature != 1.0 and temperature > 0.2 and compression_ratio > 1.0:\n",
        "            text = result['text']\n",
        "            break\n",
        "        i += 1\n",
        "        if i>3:\n",
        "            print(result)\n",
        "\n",
        "    text = text[1:]\n",
        "    print(text)\n",
        "    print(f'temperature={temperature}')\n",
        "    print(f'compression ratio={compression_ratio}')\n",
        "    print(f'no_speech_prob={no_speech_prob}')\n",
        "    text = text.replace(',','')\n",
        "    text = text.replace('.','')\n",
        "    text = text.replace('¿','')\n",
        "    text = text.replace('?','')\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "# def obtener_texto(ruta, audio):\n",
        "#     video = VideoFileClip(ruta)\n",
        "#     video.audio.write_audiofile(f'{audio}.mp3')\n",
        "#     # load audio and pad/trim it to fit 30 seconds\n",
        "#     audio = whisper.load_audio(f'{audio}.mp3')\n",
        "#     audio = whisper.pad_or_trim(audio)\n",
        "#     # make log-Mel spectrogram and move to the same device as the model\n",
        "#     mel = whisper.log_mel_spectrogram(audio).to(model_whisper.device)\n",
        "#     # detect the spoken language\n",
        "#     # _, probs = model.detect_language(mel)\n",
        "#     # print(f\"Detected language: {max(probs, key=probs.get)}\")\n",
        "#     # decode the audio\n",
        "#     options = whisper.DecodingOptions()\n",
        "#     result = whisper.decode(model_whisper, mel, options)\n",
        "#     # recognized text\n",
        "#     return result.text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPwPvqS9Y2Qh"
      },
      "source": [
        "# Generacion de video procesado, y obtencion de texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJZtCRYc81Fq"
      },
      "outputs": [],
      "source": [
        "ruta_videos = '/content/drive/MyDrive/vsr/VPHB_USFX/videos'\n",
        "ruta_dataset = '/content/drive/MyDrive/vsr/VPHB_USFX_preprocessing'\n",
        "list_videos_fa = os.listdir(ruta_videos)\n",
        "list_videos_pre = os.listdir(f'{ruta_dataset}/VPHBUSFX/video')\n",
        "list_videos = [v for v in list_videos_fa if v not in list_videos_pre]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLCa_a0j85YD",
        "outputId": "8d0e5eea-f9e3-44d6-fcfc-560d4717384c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "93"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(list_videos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrOUrv8lY4RF",
        "outputId": "2a848684-272b-469b-b7a6-7e5065539965"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/91 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "il19JIlTFbk_V1-0017.mp4\n",
            "Pasa tiempo, bueno, presión política, como siempre desde el Tribunal Supremo Electoral.\n",
            "temperature=0.0\n",
            "compression ratio=1.0\n",
            "no_speech_prob=0.1966840922832489\n",
            "pasa tiempo bueno presión política como siempre desde el tribunal supremo electoral\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 1/91 [00:23<34:44, 23.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0018.mp4\n",
            "Andan diciendo que el Congreso de la Ocaña no vale, por lo tanto, aún así somos respetuosos como instrumento político.\n",
            "temperature=0.0\n",
            "compression ratio=1.1296296296296295\n",
            "no_speech_prob=0.007685793098062277\n",
            "andan diciendo que el congreso de la ocaña no vale por lo tanto aún así somos respetuosos como instrumento político\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 2/91 [00:47<35:24, 23.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0019.mp4\n",
            "Estamos cumpliendo. Estamos cumpliendo, primero que nada, aclaramos que...\n",
            "temperature=0.0\n",
            "compression ratio=1.1746031746031746\n",
            "no_speech_prob=0.4557342231273651\n",
            "estamos cumpliendo estamos cumpliendo primero que nada aclaramos que\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 3/91 [01:06<31:26, 21.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0020.mp4\n",
            "nuestro estatuto orgánico está bien claro establece qué tiempo qué periodo tenemos para poder convocar y hacían\n",
            "temperature=0.0\n",
            "compression ratio=1.1958762886597938\n",
            "no_speech_prob=0.4829593002796173\n",
            "nuestro estatuto orgánico está bien claro establece qué tiempo qué periodo tenemos para poder convocar y hacían\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 4/91 [01:27<30:57, 21.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0021.mp4\n",
            "Congreso extraordinarios, Congreso ordinario. Por lo tanto, es establecido...\n",
            "temperature=0.0\n",
            "compression ratio=1.1\n",
            "no_speech_prob=0.15738773345947266\n",
            "congreso extraordinarios congreso ordinario por lo tanto es establecido\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  5%|▌         | 5/91 [01:43<27:46, 19.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0022.mp4\n",
            "Nosotros hemos mandado muy claro esta fecha, el 3 de abril hemos lanzado.\n",
            "temperature=0.0\n",
            "compression ratio=1.0\n",
            "no_speech_prob=0.11246731132268906\n",
            "nosotros hemos mandado muy claro esta fecha el 3 de abril hemos lanzado\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 6/91 [02:07<29:47, 21.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0024.mp4\n",
            "a la cabeza de nuestro presidente del instrumento político, a la cabeza de nuestro líder, hermano presidente Evo.\n",
            "temperature=0.0\n",
            "compression ratio=1.3218390804597702\n",
            "no_speech_prob=0.18127663433551788\n",
            "a la cabeza de nuestro presidente del instrumento político a la cabeza de nuestro líder hermano presidente evo\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 7/91 [02:26<28:24, 20.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0025.mp4\n",
            "Hemos lanzado toda la directiva y también acompañan nuestras organizaciones matrices afiliados.\n",
            "temperature=0.0\n",
            "compression ratio=1.065934065934066\n",
            "no_speech_prob=0.07807596772909164\n",
            "hemos lanzado toda la directiva y también acompañan nuestras organizaciones matrices afiliados\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  9%|▉         | 8/91 [02:45<27:38, 19.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0026.mp4\n",
            "quienes hemos parido el instrumento político. Por lo tanto, estamos cumpliendo.\n",
            "temperature=0.0\n",
            "compression ratio=1.0\n",
            "no_speech_prob=0.08226776868104935\n",
            "quienes hemos parido el instrumento político por lo tanto estamos cumpliendo\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|▉         | 9/91 [02:59<24:35, 17.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0027.mp4\n",
            "No, eso nos manda esa combinatoria el 28 de marzo.\n",
            "temperature=0.0\n",
            "compression ratio=0.9259259259259259\n",
            "no_speech_prob=0.08455711603164673\n",
            "no eso nos manda esa combinatoria el 28 de marzo\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 11%|█         | 10/91 [03:14<23:02, 17.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0028.mp4\n",
            "estamos cumpliendo dentro de 25 días deben convocar congresos. Entonces estamos cumpliendo, somos respetuosos.\n",
            "temperature=0.0\n",
            "compression ratio=1.2197802197802199\n",
            "no_speech_prob=0.24021998047828674\n",
            "estamos cumpliendo dentro de 25 días deben convocar congresos entonces estamos cumpliendo somos respetuosos\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 11/91 [03:36<25:01, 18.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0029.mp4\n",
            "Incluso de ahí llega otro instructivo del presidente, pero sin embargo, bueno, solo es de él.\n",
            "temperature=0.0\n",
            "compression ratio=1.0674157303370786\n",
            "no_speech_prob=0.16408880054950714\n",
            "incluso de ahí llega otro instructivo del presidente pero sin embargo bueno solo es de él\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 12/91 [03:57<25:39, 19.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0030.mp4\n",
            "y eso era con una fecha estableciendo hasta el 5 de mayo, pero aún también eso también hemos puesto en la computadora.\n",
            "temperature=0.0\n",
            "compression ratio=1.1862745098039216\n",
            "no_speech_prob=0.08379495143890381\n",
            "y eso era con una fecha estableciendo hasta el 5 de mayo pero aún también eso también hemos puesto en la computadora\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 14%|█▍        | 13/91 [04:18<25:37, 19.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0031.mp4\n",
            "cuál es de al que nos diga en el tribunal supremo electoral por lo tanto creo que ellos mismos se conocen\n",
            "temperature=0.0\n",
            "compression ratio=1.2183908045977012\n",
            "no_speech_prob=0.13331575691699982\n",
            "cuál es de al que nos diga en el tribunal supremo electoral por lo tanto creo que ellos mismos se conocen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 15%|█▌        | 14/91 [04:37<25:04, 19.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0032.mp4\n",
            "El legal es el 25 días, el plazo que hemos dado, donde hemos firmado la sala plena.\n",
            "temperature=0.0\n",
            "compression ratio=1.037037037037037\n",
            "no_speech_prob=0.04795937240123749\n",
            "el legal es el 25 días el plazo que hemos dado donde hemos firmado la sala plena\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 16%|█▋        | 15/91 [04:58<25:22, 20.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0033.mp4\n",
            "aclara no entonces por lo tanto hoy estamos esperando somos respetuosos para el 10 de junio estamos esperando lo que buscan\n",
            "temperature=0.0\n",
            "compression ratio=1.3977272727272727\n",
            "no_speech_prob=0.2805728614330292\n",
            "aclara no entonces por lo tanto hoy estamos esperando somos respetuosos para el 10 de junio estamos esperando lo que buscan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 18%|█▊        | 16/91 [05:26<28:06, 22.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0034.mp4\n",
            "lo que dicen que están observando\n",
            "temperature=0.0\n",
            "compression ratio=0.8717948717948718\n",
            "no_speech_prob=0.2027079463005066\n",
            "lo que dicen que están observando\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 19%|█▊        | 17/91 [05:37<23:30, 19.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0035.mp4\n",
            "¿Qué vamos a hacer nosotros con los que no son militantes? Acabo de indicar que no se ejecutiva actual.\n",
            "temperature=0.0\n",
            "compression ratio=1.105263157894737\n",
            "no_speech_prob=0.2785973846912384\n",
            "qué vamos a hacer nosotros con los que no son militantes acabo de indicar que no se ejecutiva actual\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|█▉        | 18/91 [05:59<24:20, 20.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0036.mp4\n",
            "No, ya no nos representa, nosotros no es militante.\n",
            "temperature=0.0\n",
            "compression ratio=0.9622641509433962\n",
            "no_speech_prob=0.04278503730893135\n",
            "no ya no nos representa nosotros no es militante\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 21%|██        | 19/91 [06:14<21:56, 18.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0037.mp4\n",
            "Ahora pasamos tiempo y ya descongríamos pues, no era militante.\n",
            "temperature=0.0\n",
            "compression ratio=0.9411764705882353\n",
            "no_speech_prob=0.031074898317456245\n",
            "ahora pasamos tiempo y ya descongríamos pues no era militante\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 20/91 [06:37<23:29, 19.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0038.mp4\n",
            "cuando estaba asumiendo. Después hemos sido nunca más ha demostrado. Ahora busca... Soy militante quiere decir.\n",
            "temperature=0.0\n",
            "compression ratio=1.0970873786407767\n",
            "no_speech_prob=0.04805279150605202\n",
            "cuando estaba asumiendo después hemos sido nunca más ha demostrado ahora busca soy militante quiere decir\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 23%|██▎       | 21/91 [07:02<24:57, 21.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0039.mp4\n",
            "Eso ya es desconfianza de parte de nosotros. Eso significa que nunca ha sido...\n",
            "temperature=0.0\n",
            "compression ratio=1.0675675675675675\n",
            "no_speech_prob=0.14520086348056793\n",
            "eso ya es desconfianza de parte de nosotros eso significa que nunca ha sido\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 24%|██▍       | 22/91 [07:19<23:07, 20.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0040.mp4\n",
            "del instrumento político, por lo tanto no sé qué vamos a con él desde el lugar, eso es lo que está pidiendo.\n",
            "temperature=0.0\n",
            "compression ratio=1.13\n",
            "no_speech_prob=0.09415937960147858\n",
            "del instrumento político por lo tanto no sé qué vamos a con él desde el lugar eso es lo que está pidiendo\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 25%|██▌       | 23/91 [07:37<21:48, 19.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0041.mp4\n",
            "Sin embargo, la Dirección Nacional del MASD conoce orgánicamente a nuestros dirigentes\n",
            "temperature=0.0\n",
            "compression ratio=1.0\n",
            "no_speech_prob=0.07935892790555954\n",
            "sin embargo la dirección nacional del masd conoce orgánicamente a nuestros dirigentes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 26%|██▋       | 24/91 [07:57<22:00, 19.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0042.mp4\n",
            "Con ELOSY hemos firmado la convocatoria.\n",
            "temperature=0.0\n",
            "compression ratio=0.8333333333333334\n",
            "no_speech_prob=0.15871034562587738\n",
            "con elosy hemos firmado la convocatoria\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 25/91 [08:11<19:34, 17.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0043.mp4\n",
            "están parte de la convocatoria.\n",
            "temperature=0.0\n",
            "compression ratio=0.8\n",
            "no_speech_prob=0.21914847195148468\n",
            "están parte de la convocatoria\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 29%|██▊       | 26/91 [08:22<17:09, 15.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0044.mp4\n",
            "y van a participar con sus delegados correspondientes. Por lo tanto, eso queremos aclarar, lo que no conjunda a la población.\n",
            "temperature=0.0\n",
            "compression ratio=1.1775700934579438\n",
            "no_speech_prob=0.19292250275611877\n",
            "y van a participar con sus delegados correspondientes por lo tanto eso queremos aclarar lo que no conjunda a la población\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|██▉       | 27/91 [08:41<18:02, 16.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0046.mp4\n",
            "ha pedido su denuncia del hermano evo, ¿con qué clase de persona nos quiere juntar este gobierno?\n",
            "temperature=0.0\n",
            "compression ratio=1.1\n",
            "no_speech_prob=0.10166612267494202\n",
            "ha pedido su denuncia del hermano evo con qué clase de persona nos quiere juntar este gobierno\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 31%|███       | 28/91 [08:59<17:53, 17.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0047.mp4\n",
            "Además, si es Caducos su gestión, ¿cuánto tiempo está ejecutivo?\n",
            "temperature=0.0\n",
            "compression ratio=0.8961038961038961\n",
            "no_speech_prob=0.058037254959344864\n",
            "además si es caducos su gestión cuánto tiempo está ejecutivo\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 32%|███▏      | 29/91 [09:11<16:12, 15.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0048.mp4\n",
            "Cuando yo estaba ejecutivo, hasta ahorita, ¿cuánto tiempo pasa?\n",
            "temperature=0.0\n",
            "compression ratio=0.9027777777777778\n",
            "no_speech_prob=0.06855285912752151\n",
            "cuando yo estaba ejecutivo hasta ahorita cuánto tiempo pasa\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 30/91 [09:28<16:21, 16.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0049.mp4\n",
            "Por lo tanto, ni siquiera ella ya no nos representa en la central obrera boliviana más bien. Debería convocar con ese caballero más bien.\n",
            "temperature=0.0\n",
            "compression ratio=1.25\n",
            "no_speech_prob=0.3690793216228485\n",
            "por lo tanto ni siquiera ella ya no nos representa en la central obrera boliviana más bien debería convocar con ese caballero más bien\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 34%|███▍      | 31/91 [09:54<18:55, 18.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0050.mp4\n",
            "Los que son militantes van a venir, vamos a demostrar, incluso ahora.\n",
            "temperature=0.0\n",
            "compression ratio=1.0147058823529411\n",
            "no_speech_prob=0.037339791655540466\n",
            "los que son militantes van a venir vamos a demostrar incluso ahora\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 35%|███▌      | 32/91 [10:10<17:48, 18.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0051.mp4\n",
            "Policía de la Ocaña que es de Chico, ¿quieren participar más?\n",
            "temperature=0.0\n",
            "compression ratio=0.9285714285714286\n",
            "no_speech_prob=0.18120482563972473\n",
            "policía de la ocaña que es de chico quieren participar más\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 36%|███▋      | 33/91 [10:20<15:04, 15.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0052.mp4\n",
            "También hemos escuchado los nueve departamentos han determinado para que seamos nuevamente a Anjuritio.\n",
            "temperature=0.0\n",
            "compression ratio=1.1555555555555554\n",
            "no_speech_prob=0.20258434116840363\n",
            "también hemos escuchado los nueve departamentos han determinado para que seamos nuevamente a anjuritio\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 37%|███▋      | 34/91 [10:40<16:09, 17.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0053.mp4\n",
            "la cese de la acción del trópico de Cuchabamba. Por eso es Villa Tonari, el estadio donde Vicentenario es el lugar del magno congreso que vamos a...\n",
            "temperature=0.0\n",
            "compression ratio=1.2295081967213115\n",
            "no_speech_prob=0.4146527051925659\n",
            "la cese de la acción del trópico de cuchabamba por eso es villa tonari el estadio donde vicentenario es el lugar del magno congreso que vamos a\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 35/91 [11:08<18:50, 20.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0054.mp4\n",
            "llevar en junio el 10 de junio. ¿Es legal?\n",
            "temperature=0.0\n",
            "compression ratio=0.9148936170212766\n",
            "no_speech_prob=0.3465157151222229\n",
            "llevar en junio el 10 de junio es legal\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|███▉      | 36/91 [11:20<16:18, 17.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0055.mp4\n",
            "y estamos cumpliendo con todas las normas que exigen están vigentes. Eso queremos aclarar.\n",
            "temperature=0.0\n",
            "compression ratio=1.0705882352941176\n",
            "no_speech_prob=0.021820737048983574\n",
            "y estamos cumpliendo con todas las normas que exigen están vigentes eso queremos aclarar\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 41%|████      | 37/91 [11:41<17:02, 18.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0056.mp4\n",
            "Así es, yo se presento a nivel la congeneración Bartolina, si se dé Bolivia.\n",
            "temperature=0.0\n",
            "compression ratio=0.9634146341463414\n",
            "no_speech_prob=0.11512798070907593\n",
            "así es yo se presento a nivel la congeneración bartolina si se dé bolivia\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 42%|████▏     | 38/91 [12:00<16:36, 18.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0057.mp4\n",
            "Al consenso me han elegido como miembro para que yo se presente.\n",
            "temperature=0.0\n",
            "compression ratio=0.9696969696969697\n",
            "no_speech_prob=0.03138064220547676\n",
            "al consenso me han elegido como miembro para que yo se presente\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 43%|████▎     | 39/91 [12:16<15:37, 18.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0059.mp4\n",
            "Y ya vemos si el Tribunal Supremo Electoral nos reconoce, no sé si era vamos aliente, incluso cesantes.\n",
            "temperature=0.0\n",
            "compression ratio=1.0947368421052632\n",
            "no_speech_prob=0.07860448956489563\n",
            "y ya vemos si el tribunal supremo electoral nos reconoce no sé si era vamos aliente incluso cesantes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 44%|████▍     | 40/91 [12:38<16:21, 19.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0060.mp4\n",
            "Pero aún, bueno, estoy sigo en función, por lo tanto, y voy a estar con mis pasos con mis compañeras de los nueve departamentos.\n",
            "temperature=0.0\n",
            "compression ratio=1.201834862385321\n",
            "no_speech_prob=0.17054523527622223\n",
            "pero aún bueno estoy sigo en función por lo tanto y voy a estar con mis pasos con mis compañeras de los nueve departamentos\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 45%|████▌     | 41/91 [13:02<17:15, 20.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0061.mp4\n",
            "Así hemos demostrado el 25 de marzo desde Cuchabamba, Bolivia.\n",
            "temperature=0.0\n",
            "compression ratio=0.9692307692307692\n",
            "no_speech_prob=0.1153799369931221\n",
            "así hemos demostrado el 25 de marzo desde cuchabamba bolivia\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 46%|████▌     | 42/91 [13:19<15:50, 19.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0062.mp4\n",
            "No la participación de los nueve departamentos. ¿Quién tiene la base sin pagar un centavo?\n",
            "temperature=0.0\n",
            "compression ratio=1.0108695652173914\n",
            "no_speech_prob=0.18645146489143372\n",
            "no la participación de los nueve departamentos quién tiene la base sin pagar un centavo\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 43/91 [13:49<18:07, 22.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0063.mp4\n",
            "ni sin intromisión de los funcionarios designados\n",
            "temperature=0.0\n",
            "compression ratio=0.8928571428571429\n",
            "no_speech_prob=0.11338789016008377\n",
            "ni sin intromisión de los funcionarios designados\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 44/91 [14:01<15:12, 19.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0064.mp4\n",
            "Hemos demostrado nuestra convocatoria en la confederación Bartolina Sista de Bolivia.\n",
            "temperature=0.0\n",
            "compression ratio=1.036144578313253\n",
            "no_speech_prob=0.23224882781505585\n",
            "hemos demostrado nuestra convocatoria en la confederación bartolina sista de bolivia\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 49%|████▉     | 45/91 [14:17<14:07, 18.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0065.mp4\n",
            "tiene su estructura, tiene sus afiliados.\n",
            "temperature=0.0\n",
            "compression ratio=0.9318181818181818\n",
            "no_speech_prob=0.19836069643497467\n",
            "tiene su estructura tiene sus afiliados\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 51%|█████     | 46/91 [14:28<12:04, 16.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0066.mp4\n",
            "tiene su base y va a demostrar donde sea. Así hemos demostrado desde nuestro ampliado de la conversación campesinos de Bolivia, en nuestro congreso de Elia.\n",
            "temperature=0.0\n",
            "compression ratio=1.3389830508474576\n",
            "no_speech_prob=0.23381057381629944\n",
            "tiene su base y va a demostrar donde sea así hemos demostrado desde nuestro ampliado de la conversación campesinos de bolivia en nuestro congreso de elia\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 52%|█████▏    | 47/91 [14:54<14:05, 19.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0067.mp4\n",
            "de cuatro cañadas, nuestro aniversario del instrumento político, eso es la base.\n",
            "temperature=0.0\n",
            "compression ratio=1.0379746835443038\n",
            "no_speech_prob=0.060341812670230865\n",
            "de cuatro cañadas nuestro aniversario del instrumento político eso es la base\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 48/91 [15:13<13:41, 19.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0068.mp4\n",
            "sem pagar funcionários, sem estar com coteus.\n",
            "temperature=0.0\n",
            "compression ratio=0.92\n",
            "no_speech_prob=0.2130979746580124\n",
            "sem pagar funcionários sem estar com coteus\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 54%|█████▍    | 49/91 [15:26<12:11, 17.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0069.mp4\n",
            "con ninguna presión, con ninguna condición, es militante de todo corazón. Eso demostramos.\n",
            "temperature=0.0\n",
            "compression ratio=1.1341463414634145\n",
            "no_speech_prob=0.03338245302438736\n",
            "con ninguna presión con ninguna condición es militante de todo corazón eso demostramos\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 55%|█████▍    | 50/91 [15:45<12:05, 17.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0070.mp4\n",
            "Únicamente y cabalmente lo decimos al Tribunal Supremo Electoral. Ahí lo tiene la lista de los miembros.\n",
            "temperature=0.0\n",
            "compression ratio=1.0707070707070707\n",
            "no_speech_prob=0.09721101820468903\n",
            "únicamente y cabalmente lo decimos al tribunal supremo electoral ahí lo tiene la lista de los miembros\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 56%|█████▌    | 51/91 [16:02<11:46, 17.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0071.mp4\n",
            "Quienes somos elegidos por el más no congreso, quienes somos reconocidos legalmente, legítimamente como miembros.\n",
            "temperature=0.0\n",
            "compression ratio=1.25\n",
            "no_speech_prob=0.05727575719356537\n",
            "quienes somos elegidos por el más no congreso quienes somos reconocidos legalmente legítimamente como miembros\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 57%|█████▋    | 52/91 [16:30<13:29, 20.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0072.mp4\n",
            "de la dirección nacional del MAS lo tienen ellos la lista correspondiente. Somos 14.\n",
            "temperature=0.0\n",
            "compression ratio=1.0119047619047619\n",
            "no_speech_prob=0.15258364379405975\n",
            "de la dirección nacional del mas lo tienen ellos la lista correspondiente somos 14\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 58%|█████▊    | 53/91 [16:47<12:24, 19.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0074.mp4\n",
            "Dos que sí, nos han traicionado y se han ido por algunas razones no, ni siquiera son militantes. Por lo tanto...\n",
            "temperature=0.0\n",
            "compression ratio=1.153061224489796\n",
            "no_speech_prob=0.08052953332662582\n",
            "dos que sí nos han traicionado y se han ido por algunas razones no ni siquiera son militantes por lo tanto\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 59%|█████▉    | 54/91 [17:11<12:49, 20.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0076.mp4\n",
            "Cuíremes a la cabeza de nuestro presidente Evo, eso queremos aclarar, claro, tiene que ser claro ante la opinión pública, únicamente queremos en cabal.\n",
            "temperature=0.0\n",
            "compression ratio=1.28099173553719\n",
            "no_speech_prob=0.12583027780056\n",
            "cuíremes a la cabeza de nuestro presidente evo eso queremos aclarar claro tiene que ser claro ante la opinión pública únicamente queremos en cabal\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 55/91 [17:38<13:42, 22.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0077.mp4\n",
            "Lo que estoy aclarando, ellos que cumplan a esta la ley 1096\n",
            "temperature=0.0\n",
            "compression ratio=0.9836065573770492\n",
            "no_speech_prob=0.08602142333984375\n",
            "lo que estoy aclarando ellos que cumplan a esta la ley 1096\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 62%|██████▏   | 56/91 [17:57<12:33, 21.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0078.mp4\n",
            "Ahí está el Estatuto Orgánico del Instrumento Político. Únicamente estamos pidiendo eso nosotros.\n",
            "temperature=0.0\n",
            "compression ratio=1.0515463917525774\n",
            "no_speech_prob=0.13666121661663055\n",
            "ahí está el estatuto orgánico del instrumento político únicamente estamos pidiendo eso nosotros\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 63%|██████▎   | 57/91 [18:14<11:22, 20.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0079.mp4\n",
            "respetuosamente que se pronuncie para que venga como veedor o al final de cuentas como supervisor\n",
            "temperature=0.0\n",
            "compression ratio=1.2435897435897436\n",
            "no_speech_prob=0.10698545724153519\n",
            "respetuosamente que se pronuncie para que venga como veedor o al final de cuentas como supervisor\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 64%|██████▎   | 58/91 [18:40<12:03, 21.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0080.mp4\n",
            "para que haga seguimiento a nuestro Congreso, como vamos a demostrar una vez más.\n",
            "temperature=0.0\n",
            "compression ratio=1.0123456790123457\n",
            "no_speech_prob=0.2121880054473877\n",
            "para que haga seguimiento a nuestro congreso como vamos a demostrar una vez más\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 65%|██████▍   | 59/91 [18:56<10:48, 20.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0084.mp4\n",
            "Vamos a participar una vez más para llevar adelante nuestro Congreso de nuestra gloriosa con...\n",
            "temperature=0.0\n",
            "compression ratio=1.0909090909090908\n",
            "no_speech_prob=0.1858447939157486\n",
            "vamos a participar una vez más para llevar adelante nuestro congreso de nuestra gloriosa con\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 66%|██████▌   | 60/91 [19:16<10:19, 20.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0085.mp4\n",
            "de nuestro glorioso instrumento político, con nuestras organizaciones matrices.\n",
            "temperature=0.0\n",
            "compression ratio=1.0389610389610389\n",
            "no_speech_prob=0.21869221329689026\n",
            "de nuestro glorioso instrumento político con nuestras organizaciones matrices\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 61/91 [19:30<09:13, 18.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0086.mp4\n",
            "Agiliados fundadores del instrumento político. Estamos claros, nosotros vamos a demostrar.\n",
            "temperature=0.0\n",
            "compression ratio=1.058139534883721\n",
            "no_speech_prob=0.06619718670845032\n",
            "agiliados fundadores del instrumento político estamos claros nosotros vamos a demostrar\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 68%|██████▊   | 62/91 [19:47<08:41, 18.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0087.mp4\n",
            "Somos unas de región, somos muy educadas, con mucha altura, con mucha disciplina.\n",
            "temperature=0.0\n",
            "compression ratio=1.0789473684210527\n",
            "no_speech_prob=0.09338545054197311\n",
            "somos unas de región somos muy educadas con mucha altura con mucha disciplina\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 69%|██████▉   | 63/91 [20:05<08:17, 17.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0088.mp4\n",
            "Estamos con brazos abiertos para poder decidir desde nuestro estadio de Villa Tunares, si ellos así quieren.\n",
            "temperature=0.0\n",
            "compression ratio=1.1237113402061856\n",
            "no_speech_prob=0.18170876801013947\n",
            "estamos con brazos abiertos para poder decidir desde nuestro estadio de villa tunares si ellos así quieren\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 64/91 [20:24<08:16, 18.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0089.mp4\n",
            "que somos pocos, vamos a demostrar que sí un estadio va a ser lleno y se ventando para este congreso. Vamos, estamos preparados.\n",
            "temperature=0.0\n",
            "compression ratio=1.2524271844660195\n",
            "no_speech_prob=0.4489167332649231\n",
            "que somos pocos vamos a demostrar que sí un estadio va a ser lleno y se ventando para este congreso vamos estamos preparados\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 71%|███████▏  | 65/91 [20:51<09:00, 20.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0090.mp4\n",
            "los nueve departamentos, además, a pedido de nuestros dirigentes de los nueve departamentos\n",
            "temperature=0.0\n",
            "compression ratio=1.295774647887324\n",
            "no_speech_prob=0.13936296105384827\n",
            "los nueve departamentos además a pedido de nuestros dirigentes de los nueve departamentos\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 66/91 [21:07<08:05, 19.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0091.mp4\n",
            "Se ha ampliado, incluso el lugar se ha decidido. El Policía de la Ocaña es muy chiquito, queremos un poco más participar.\n",
            "temperature=0.0\n",
            "compression ratio=1.0973451327433628\n",
            "no_speech_prob=0.12016770243644714\n",
            "se ha ampliado incluso el lugar se ha decidido el policía de la ocaña es muy chiquito queremos un poco más participar\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 74%|███████▎  | 67/91 [21:26<07:40, 19.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0092.mp4\n",
            "Bienvenidos, no vamos a ceder, bienvenidos todos los militantes que somos de todo corazón\n",
            "temperature=0.0\n",
            "compression ratio=1.1111111111111112\n",
            "no_speech_prob=0.3252826929092407\n",
            "bienvenidos no vamos a ceder bienvenidos todos los militantes que somos de todo corazón\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 75%|███████▍  | 68/91 [21:43<07:12, 18.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0093.mp4\n",
            "que nunca vamos a claudicar, no por el cargo nomás vamos a estar, estemos donde estemos\n",
            "temperature=0.0\n",
            "compression ratio=1.1733333333333333\n",
            "no_speech_prob=0.2289620190858841\n",
            "que nunca vamos a claudicar no por el cargo nomás vamos a estar estemos donde estemos\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 76%|███████▌  | 69/91 [22:03<06:55, 18.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0094.mp4\n",
            "Tenemos que defender nuestro instrumento político y así reconociendo el liderazgo.\n",
            "temperature=0.0\n",
            "compression ratio=1.037037037037037\n",
            "no_speech_prob=0.12333507835865021\n",
            "tenemos que defender nuestro instrumento político y así reconociendo el liderazgo\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 77%|███████▋  | 70/91 [22:20<06:25, 18.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0095.mp4\n",
            "Quién nos ha demostrado en 14 años el trabajo en nuestro país, la transformación de Bolivia. Eso es, vamos a continuar a la cabeza de nuestro líder, hermano Evo.\n",
            "temperature=0.0\n",
            "compression ratio=1.2116788321167884\n",
            "no_speech_prob=0.026294777169823647\n",
            "quién nos ha demostrado en 14 años el trabajo en nuestro país la transformación de bolivia eso es vamos a continuar a la cabeza de nuestro líder hermano evo\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 78%|███████▊  | 71/91 [22:47<06:57, 20.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "5Dil7rQ_FnM_V1-0002.mp4\n",
            "lamentablemente tres han perdido la vida por intoxicación\n",
            "temperature=0.0\n",
            "compression ratio=0.9206349206349206\n",
            "no_speech_prob=0.1707785278558731\n",
            "lamentablemente tres han perdido la vida por intoxicación\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 79%|███████▉  | 72/91 [22:58<05:45, 18.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "5Dil7rQ_FnM_V1-0003.mp4\n",
            "muy profundo lo que ha ocasionado que se sature.\n",
            "temperature=0.0\n",
            "compression ratio=0.96\n",
            "no_speech_prob=0.479047030210495\n",
            "muy profundo lo que ha ocasionado que se sature\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 73/91 [23:17<05:29, 18.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0002.mp4\n",
            "Queremos aclarar ante la población...\n",
            "temperature=0.0\n",
            "compression ratio=0.8260869565217391\n",
            "no_speech_prob=0.06448287516832352\n",
            "queremos aclarar ante la población\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 81%|████████▏ | 74/91 [23:28<04:35, 16.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0023.mp4\n",
            "la convocatoria nacional.\n",
            "temperature=0.0\n",
            "compression ratio=0.7575757575757576\n",
            "no_speech_prob=0.0371459536254406\n",
            "la convocatoria nacional\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 82%|████████▏ | 75/91 [23:38<03:48, 14.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0004.mp4\n",
            "Quem não é militante do instrumento?\n",
            "temperature=0.0\n",
            "compression ratio=0.8260869565217391\n",
            "no_speech_prob=0.06251130998134613\n",
            "quem não é militante do instrumento\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 84%|████████▎ | 76/91 [23:50<03:25, 13.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0045.mp4\n",
            "¿Qué vamos a hacer nosotros? ¿Qué vamos a hacer con el huarache?\n",
            "temperature=0.0\n",
            "compression ratio=1.1724137931034482\n",
            "no_speech_prob=0.03739936277270317\n",
            "qué vamos a hacer nosotros qué vamos a hacer con el huarache\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 85%|████████▍ | 77/91 [24:00<02:52, 12.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0058.mp4\n",
            "¿Qué culpa tenemos nosotros si hemos cumplido?\n",
            "temperature=0.0\n",
            "compression ratio=0.9230769230769231\n",
            "no_speech_prob=0.05735951289534569\n",
            "qué culpa tenemos nosotros si hemos cumplido\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 86%|████████▌ | 78/91 [24:09<02:29, 11.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0073.mp4\n",
            "14 están dos con servicio internacional son embajadores\n",
            "temperature=0.0\n",
            "compression ratio=0.9032258064516129\n",
            "no_speech_prob=0.3643065392971039\n",
            "14 están dos con servicio internacional son embajadores\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 87%|████████▋ | 79/91 [24:22<02:22, 11.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0082.mp4\n",
            "con mucha educación vamos a demostrar\n",
            "temperature=0.0\n",
            "compression ratio=0.8444444444444444\n",
            "no_speech_prob=0.08648166805505753\n",
            "con mucha educación vamos a demostrar\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 88%|████████▊ | 80/91 [24:30<01:57, 10.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0081.mp4\n",
            "con mucha disciplina y con mucha altura\n",
            "temperature=0.0\n",
            "compression ratio=0.975\n",
            "no_speech_prob=0.28032153844833374\n",
            "con mucha disciplina y con mucha altura\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 89%|████████▉ | 81/91 [24:39<01:42, 10.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0075.mp4\n",
            "y los demás, los diez miembros estamos firmes.\n",
            "temperature=0.0\n",
            "compression ratio=0.9791666666666666\n",
            "no_speech_prob=0.07548757642507553\n",
            "y los demás los diez miembros estamos firmes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 82/91 [24:51<01:37, 10.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "il19JIlTFbk_V1-0083.mp4\n",
            "con nuestras bases todos los delegados militantes\n",
            "temperature=0.0\n",
            "compression ratio=0.9423076923076923\n",
            "no_speech_prob=0.02439810335636139\n",
            "con nuestras bases todos los delegados militantes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 91%|█████████ | 83/91 [25:01<01:24, 10.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "kBqQfazsWUw_V1-0001.mp4\n",
            "obviamente no se ha sorprendido particularmente a todos\n",
            "temperature=0.0\n",
            "compression ratio=0.9821428571428571\n",
            "no_speech_prob=0.02338552288711071\n",
            "obviamente no se ha sorprendido particularmente a todos\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 92%|█████████▏| 84/91 [25:21<01:34, 13.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "kBqQfazsWUw_V1-0002.mp4\n",
            "Hermanos bolivianos, esta designación repentina.\n",
            "temperature=0.0\n",
            "compression ratio=0.8909090909090909\n",
            "no_speech_prob=0.015744689851999283\n",
            "hermanos bolivianos esta designación repentina\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 93%|█████████▎| 85/91 [25:36<01:22, 13.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "kBqQfazsWUw_V1-0011.mp4\n",
            "de que los vocales y particularmente la vocal\n",
            "temperature=0.0\n",
            "compression ratio=0.9574468085106383\n",
            "no_speech_prob=0.03343363478779793\n",
            "de que los vocales y particularmente la vocal\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 95%|█████████▍| 86/91 [25:47<01:05, 13.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "kBqQfazsWUw_V1-0004.mp4\n",
            "al señor Gustavo Ávila, quien es su hombre de confianza\n",
            "temperature=0.0\n",
            "compression ratio=0.8769230769230769\n",
            "no_speech_prob=0.07328496128320694\n",
            "al señor gustavo ávila quien es su hombre de confianza\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 96%|█████████▌| 87/91 [26:08<01:00, 15.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "kBqQfazsWUw_V1-0003.mp4\n",
            "Es decir, el gobierno ha posesionado.\n",
            "temperature=0.0\n",
            "compression ratio=0.8222222222222222\n",
            "no_speech_prob=0.010498384945094585\n",
            "es decir el gobierno ha posesionado\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 97%|█████████▋| 88/91 [26:27<00:49, 16.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "kBqQfazsWUw_V1-0007.mp4\n",
            "a cambio de Dina Chuquimia, del vocal de Dina Chuquimia\n",
            "temperature=0.0\n",
            "compression ratio=1.1956521739130435\n",
            "no_speech_prob=0.030034035444259644\n",
            "a cambio de dina chuquimia del vocal de dina chuquimia\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 98%|█████████▊| 89/91 [26:41<00:31, 15.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "kBqQfazsWUw_V1-0006.mp4\n",
            "Ahora, nuevamente nos sorprende que lo designan\n",
            "temperature=0.0\n",
            "compression ratio=0.8545454545454545\n",
            "no_speech_prob=0.04477009177207947\n",
            "ahora nuevamente nos sorprende que lo designan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 99%|█████████▉| 90/91 [27:01<00:16, 16.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "kBqQfazsWUw_V1-0016.mp4\n",
            "que son emitidos para su cumplimiento dentro de las funciones del Tribunal Supremo Electoral.\n",
            "temperature=0.0\n",
            "compression ratio=1.1204819277108433\n",
            "no_speech_prob=0.014407145790755749\n",
            "que son emitidos para su cumplimiento dentro de las funciones del tribunal supremo electoral\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 91/91 [27:23<00:00, 18.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "video_dataloader = AVSRDataLoader(modality=\"video\", detector=\"retinaface\", convert_gray=False)\n",
        "audio_dataloader = AVSRDataLoader(modality=\"audio\")\n",
        "\n",
        "for data_filename in tqdm(list_videos[2:200]):\n",
        "    print(data_filename)\n",
        "    name = data_filename.split('.')[0]\n",
        "    ruta = f'{ruta_videos}/{data_filename}'\n",
        "    # Obtener video y texto\n",
        "    text_data = obtener_texto(ruta, name)\n",
        "    print(text_data)\n",
        "    video_data = video_dataloader.load_data(ruta)\n",
        "    audio_data = audio_dataloader.load_data(ruta)\n",
        "    # Guardar texto y video\n",
        "    output_video_path = f'{ruta_dataset}/VPHBUSFX/video/{name}.mp4'\n",
        "    output_audio_path = f'{ruta_dataset}/VPHBUSFX/video/{name}.wav'\n",
        "    output_text_path = f'{ruta_dataset}/VPHBUSFX/text/{name}.txt'\n",
        "    # save_vid_txt(output_video_path, output_text_path,\n",
        "    #              video_data, text_data)\n",
        "    save_vid_aud_txt(output_video_path, output_audio_path, output_text_path,\n",
        "                    video_data, audio_data, text_data,\n",
        "                    video_fps=25, audio_sample_rate=16000)\n",
        "    print('--------------------------------------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ly65uzLSD_rW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5jVbsPynfIP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Vf5mUY66pRJ"
      },
      "source": [
        "# TextTransform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "n_Mh7W8j66-Q"
      },
      "outputs": [],
      "source": [
        "import sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "U2pjDXiA6o0S"
      },
      "outputs": [],
      "source": [
        "SP_MODEL_PATH = os.path.join(\n",
        "    os.path.dirname(os.path.dirname(os.path.abspath(''))),\n",
        "    \"content\",\n",
        "    \"drive\",\n",
        "    \"MyDrive\",\n",
        "    \"vsr\",\n",
        "    \"Models\",\n",
        "    \"SentencePiece_castellano_v4\",\n",
        "    \"unigram5000.model\",\n",
        ")\n",
        "\n",
        "DICT_PATH = os.path.join(\n",
        "    os.path.dirname(os.path.dirname(os.path.abspath(''))),\n",
        "    \"content\",\n",
        "    \"drive\",\n",
        "    \"MyDrive\",\n",
        "    \"vsr\",\n",
        "    \"Models\",\n",
        "    \"SentencePiece_castellano_v4\",\n",
        "    \"unigram5000_units.txt\",\n",
        ")\n",
        "\n",
        "\n",
        "class TextTransform:\n",
        "    \"\"\"Mapping Dictionary Class for SentencePiece tokenization.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        sp_model_path=SP_MODEL_PATH,\n",
        "        dict_path=DICT_PATH,\n",
        "    ):\n",
        "\n",
        "        # Load SentencePiece model\n",
        "        self.spm = sentencepiece.SentencePieceProcessor(model_file=sp_model_path)\n",
        "\n",
        "        # Load units and create dictionary\n",
        "        units = open(dict_path, encoding='utf8').read().splitlines()\n",
        "        self.hashmap = {unit.split()[0]: unit.split()[-1] for unit in units}\n",
        "        # 0 will be used for \"blank\" in CTC\n",
        "        self.token_list = [\"<blank>\"] + list(self.hashmap.keys()) + [\"<eos>\"]\n",
        "        self.ignore_id = -1\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        tokens = self.spm.EncodeAsPieces(text)\n",
        "        token_ids = [self.hashmap.get(token, self.hashmap[\"<unk>\"]) for token in tokens]\n",
        "        return torch.tensor(list(map(int, token_ids)))\n",
        "\n",
        "    def post_process(self, token_ids):\n",
        "        token_ids = token_ids[token_ids != -1]\n",
        "        text = self._ids_to_str(token_ids, self.token_list)\n",
        "        text = text.replace(\"\\u2581\", \" \").strip()\n",
        "        return text\n",
        "\n",
        "    def _ids_to_str(self, token_ids, char_list):\n",
        "        token_as_list = [char_list[idx] for idx in token_ids]\n",
        "        return \"\".join(token_as_list).replace(\"<space>\", \" \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bu4mQFgBzwGY"
      },
      "source": [
        "# Tokenizer y generacion de csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "z2lOzc6P6Xio"
      },
      "outputs": [],
      "source": [
        "text_transform = TextTransform()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "c0EKk85mnfFB"
      },
      "outputs": [],
      "source": [
        "ruta = \"/content/drive/MyDrive/vsr/VPHB_USFX_preprocessing\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "Yl3NGeGd0_Ev",
        "outputId": "f16332dd-aa0e-4c51-a22f-0ae61b95cf3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1227/1227 [05:26<00:00,  3.76it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Dataset                           ruta  input_length  \\\n",
              "0     VPHBUSFX  video/iRF5d2N5wos_V1-0016.mp4           193   \n",
              "1     VPHBUSFX  video/iRF5d2N5wos_V1-0017.mp4           172   \n",
              "2     VPHBUSFX  video/iRF5d2N5wos_V1-0018.mp4           222   \n",
              "3     VPHBUSFX  video/iRF5d2N5wos_V1-0019.mp4            97   \n",
              "4     VPHBUSFX  video/iRF5d2N5wos_V1-0020.mp4           107   \n",
              "...        ...                            ...           ...   \n",
              "1222  VPHBUSFX  video/mZxweoeJEcc_V1-0017.mp4           355   \n",
              "1223  VPHBUSFX  video/mZxweoeJEcc_V1-0018.mp4           291   \n",
              "1224  VPHBUSFX  video/mZxweoeJEcc_V1-0019.mp4           235   \n",
              "1225  VPHBUSFX  video/mZxweoeJEcc_V1-0020.mp4           254   \n",
              "1226  VPHBUSFX  video/mZxweoeJEcc_V1-0021.mp4           269   \n",
              "\n",
              "                                               token_id  \n",
              "0     4 4076 4 2809 4 1919 4 1023 4 853 4 3244 4 191...  \n",
              "1     4 4084 4 3577 4 4076 4 1612 4 3527 4 3244 4 23...  \n",
              "2     4 2361 4 329 4 2655 4 1517 4 3107 4 1090 4 158...  \n",
              "3     4 2655 4 1914 4 1322 4 1914 4 1523 4 1023 4 18...  \n",
              "4     4 1349 4 2019 4 1510 4 3504 4 1870 4 3667 4 19...  \n",
              "...                                                 ...  \n",
              "1222  4 3750 4 3244 4 542 4 2243 4 2234 4 1517 4 234...  \n",
              "1223  4 3158 4 2915 4 3037 4 2243 4 4006 4 2781 4 26...  \n",
              "1224  4 1385 4 3906 4 546 4 3244 4 3783 4 1385 4 282...  \n",
              "1225  4 3571 4 1368 4 3134 4 554 4 3244 4 2674 4 325...  \n",
              "1226  4 1572 4 1905 4 1385 4 3519 4 2832 4 2243 4 30...  \n",
              "\n",
              "[1227 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-539283d2-55e9-4af8-8e2d-e7bdbc895f00\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataset</th>\n",
              "      <th>ruta</th>\n",
              "      <th>input_length</th>\n",
              "      <th>token_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>VPHBUSFX</td>\n",
              "      <td>video/iRF5d2N5wos_V1-0016.mp4</td>\n",
              "      <td>193</td>\n",
              "      <td>4 4076 4 2809 4 1919 4 1023 4 853 4 3244 4 191...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>VPHBUSFX</td>\n",
              "      <td>video/iRF5d2N5wos_V1-0017.mp4</td>\n",
              "      <td>172</td>\n",
              "      <td>4 4084 4 3577 4 4076 4 1612 4 3527 4 3244 4 23...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>VPHBUSFX</td>\n",
              "      <td>video/iRF5d2N5wos_V1-0018.mp4</td>\n",
              "      <td>222</td>\n",
              "      <td>4 2361 4 329 4 2655 4 1517 4 3107 4 1090 4 158...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>VPHBUSFX</td>\n",
              "      <td>video/iRF5d2N5wos_V1-0019.mp4</td>\n",
              "      <td>97</td>\n",
              "      <td>4 2655 4 1914 4 1322 4 1914 4 1523 4 1023 4 18...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>VPHBUSFX</td>\n",
              "      <td>video/iRF5d2N5wos_V1-0020.mp4</td>\n",
              "      <td>107</td>\n",
              "      <td>4 1349 4 2019 4 1510 4 3504 4 1870 4 3667 4 19...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1222</th>\n",
              "      <td>VPHBUSFX</td>\n",
              "      <td>video/mZxweoeJEcc_V1-0017.mp4</td>\n",
              "      <td>355</td>\n",
              "      <td>4 3750 4 3244 4 542 4 2243 4 2234 4 1517 4 234...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1223</th>\n",
              "      <td>VPHBUSFX</td>\n",
              "      <td>video/mZxweoeJEcc_V1-0018.mp4</td>\n",
              "      <td>291</td>\n",
              "      <td>4 3158 4 2915 4 3037 4 2243 4 4006 4 2781 4 26...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1224</th>\n",
              "      <td>VPHBUSFX</td>\n",
              "      <td>video/mZxweoeJEcc_V1-0019.mp4</td>\n",
              "      <td>235</td>\n",
              "      <td>4 1385 4 3906 4 546 4 3244 4 3783 4 1385 4 282...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1225</th>\n",
              "      <td>VPHBUSFX</td>\n",
              "      <td>video/mZxweoeJEcc_V1-0020.mp4</td>\n",
              "      <td>254</td>\n",
              "      <td>4 3571 4 1368 4 3134 4 554 4 3244 4 2674 4 325...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1226</th>\n",
              "      <td>VPHBUSFX</td>\n",
              "      <td>video/mZxweoeJEcc_V1-0021.mp4</td>\n",
              "      <td>269</td>\n",
              "      <td>4 1572 4 1905 4 1385 4 3519 4 2832 4 2243 4 30...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1227 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-539283d2-55e9-4af8-8e2d-e7bdbc895f00')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-539283d2-55e9-4af8-8e2d-e7bdbc895f00 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-539283d2-55e9-4af8-8e2d-e7bdbc895f00');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-15ef233e-dcfe-445a-ab7c-fc425578943b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-15ef233e-dcfe-445a-ab7c-fc425578943b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-15ef233e-dcfe-445a-ab7c-fc425578943b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_78fe0c05-9df5-459b-8f00-07c089354533\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_csv')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_78fe0c05-9df5-459b-8f00-07c089354533 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_csv');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_csv",
              "summary": "{\n  \"name\": \"df_csv\",\n  \"rows\": 1227,\n  \"fields\": [\n    {\n      \"column\": \"Dataset\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"VPHBUSFX\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ruta\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1227,\n        \"samples\": [\n          \"video/4yquiL-r1J0_V1-0015.mp4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"input_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 98,\n        \"min\": 54,\n        \"max\": 670,\n        \"num_unique_values\": 369,\n        \"samples\": [\n          447\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"token_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1218,\n        \"samples\": [\n          \"4 3007 4 2694 4 2625 4 4077 4 3010 4 1899 4 1435 4 3366 4 53 4 1599 4 3740 4 1023 4 1734\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "list_video = [video for video in os.listdir(f'{ruta}/VPHBUSFX/video') if video.split('.')[1]=='mp4']\n",
        "list_video_text = [[f'{ruta}/VPHBUSFX/video/{name}.mp4',f'{ruta}/VPHBUSFX/text/{name}.txt'] for name in [n.split('.')[0] for n in list_video]]\n",
        "list_csv = []\n",
        "for r_vid, r_text in tqdm(list_video_text):\n",
        "    video = torchvision.io.read_video(r_vid, pts_unit=\"sec\")[0].numpy()\n",
        "    text = open(r_text, 'r').read()\n",
        "    token_id_str = \" \".join(\n",
        "            map(str, [_.item() for _ in text_transform.tokenize(text)])\n",
        "    )\n",
        "    name_video = r_vid.split('/')[-1]\n",
        "    list_csv.append(['VPHBUSFX', f'video/{name_video}', video.shape[0], token_id_str])\n",
        "df_csv = pd.DataFrame(list_csv, columns=['Dataset','ruta','input_length','token_id'])\n",
        "df_csv.to_csv(f'{ruta}/labels/VPHBUSFX_unigram5000.csv')\n",
        "df_csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3pA7PK_-z6c"
      },
      "source": [
        "# Obtener train, val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "vz2kU0p-1U9U"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "gPKGInxa2f9j"
      },
      "outputs": [],
      "source": [
        "df_train, df_test = train_test_split(df_csv, test_size=0.08)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPYiFpJs3DYU",
        "outputId": "0235c523-ab2b-4444-c36b-d39135a06825"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1128, 4), (99, 4))"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "df_train.shape, df_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "-zu5jv8E99-7"
      },
      "outputs": [],
      "source": [
        "df_train.to_csv(f'{ruta}/labels/VPHBUSFX_unigram5000_train.csv')\n",
        "df_test.to_csv(f'{ruta}/labels/VPHBUSFX_unigram5000_val.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0dxNRb6-3G-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmKRDsSp-2_s"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RN8l2ftSeKiq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "1jLgxJNjUvK0",
        "2rIk5Xf7Urtz",
        "zAvtziY3UFbe",
        "CiL6IrYoYdOy",
        "Wq50mSe0jOLG",
        "yPwPvqS9Y2Qh"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}